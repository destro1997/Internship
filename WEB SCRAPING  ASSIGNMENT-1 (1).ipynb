{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "517b045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Main Page'],\n",
       " [\"From today's featured article\"],\n",
       " ['Did you know\\xa0...'],\n",
       " ['In the news'],\n",
       " ['On this day'],\n",
       " [\"Today's featured picture\"],\n",
       " ['Other areas of Wikipedia'],\n",
       " [\"Wikipedia's sister projects\"],\n",
       " ['Wikipedia languages'],\n",
       " ['Navigation menu'],\n",
       " ['', 'Personal tools', ''],\n",
       " ['', 'Namespaces', ''],\n",
       " ['', 'Variants', 'expanded', 'collapsed', ''],\n",
       " ['', 'Views', ''],\n",
       " ['', 'More', 'expanded', 'collapsed', ''],\n",
       " ['', 'Search', ''],\n",
       " ['', 'Navigation', ''],\n",
       " ['', 'Contribute', ''],\n",
       " ['', 'Tools', ''],\n",
       " ['', 'Print/export', ''],\n",
       " ['', 'In other projects', ''],\n",
       " ['', 'Languages', '']]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#display all the header tags from wikipedia.org.\n",
    "\n",
    "\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "soup = BeautifulSoup(page.content)\n",
    "header_tags = soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "header_tags\n",
    "\n",
    "ab = []\n",
    "for abc in header_tags:\n",
    "    abc = abc.get_text().split('\\n')\n",
    "    ab.append(abc)\n",
    "    \n",
    "ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e914b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies</th>\n",
       "      <th>year</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>(1993)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Inception</td>\n",
       "      <td>(2010)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>(1999)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Il buono, il brutto, il cattivo</td>\n",
       "      <td>(1966)</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Matrix</td>\n",
       "      <td>(1999)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Goodfellas</td>\n",
       "      <td>(1990)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Star Wars: Episode V - The Empire Strikes Back</td>\n",
       "      <td>(1980)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>(1975)</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Gisaengchung</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>(2014)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cidade de Deus</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sen to Chihiro no kamikakushi</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Saving Private Ryan</td>\n",
       "      <td>(1998)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>(1999)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>La vita è bella</td>\n",
       "      <td>(1997)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Se7en</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Silence of the Lambs</td>\n",
       "      <td>(1991)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Star Wars</td>\n",
       "      <td>(1977)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Seppuku</td>\n",
       "      <td>(1962)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Shichinin no samurai</td>\n",
       "      <td>(1954)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>It's a Wonderful Life</td>\n",
       "      <td>(1946)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>(2014)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>(2011)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Prestige</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The Departed</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The Pianist</td>\n",
       "      <td>(2002)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Gladiator</td>\n",
       "      <td>(2000)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>American History X</td>\n",
       "      <td>(1998)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The Usual Suspects</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Léon</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Terminator 2: Judgment Day</td>\n",
       "      <td>(1991)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Nuovo Cinema Paradiso</td>\n",
       "      <td>(1988)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Hotaru no haka</td>\n",
       "      <td>(1988)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Back to the Future</td>\n",
       "      <td>(1985)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>(1968)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>(1960)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>(1954)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>(1942)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>(1936)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               movies    year ratings\n",
       "0                            The Shawshank Redemption  (1994)     9.3\n",
       "1                                       The Godfather  (1972)     9.2\n",
       "2                                     The Dark Knight  (2008)     9.0\n",
       "3                              The Godfather: Part II  (1974)     9.0\n",
       "4                                        12 Angry Men  (1957)     9.0\n",
       "5       The Lord of the Rings: The Return of the King  (2003)     8.9\n",
       "6                                        Pulp Fiction  (1994)     8.9\n",
       "7                                    Schindler's List  (1993)     8.9\n",
       "8                                           Inception  (2010)     8.8\n",
       "9                                          Fight Club  (1999)     8.8\n",
       "10  The Lord of the Rings: The Fellowship of the Ring  (2001)     8.8\n",
       "11                                       Forrest Gump  (1994)     8.8\n",
       "12                    Il buono, il brutto, il cattivo  (1966)     8.8\n",
       "13              The Lord of the Rings: The Two Towers  (2002)     8.7\n",
       "14                                         The Matrix  (1999)     8.7\n",
       "15                                         Goodfellas  (1990)     8.7\n",
       "16     Star Wars: Episode V - The Empire Strikes Back  (1980)     8.7\n",
       "17                    One Flew Over the Cuckoo's Nest  (1975)     8.7\n",
       "18                                       Gisaengchung  (2019)     8.6\n",
       "19                                       Interstellar  (2014)     8.6\n",
       "20                                     Cidade de Deus  (2002)     8.6\n",
       "21                      Sen to Chihiro no kamikakushi  (2001)     8.6\n",
       "22                                Saving Private Ryan  (1998)     8.6\n",
       "23                                     The Green Mile  (1999)     8.6\n",
       "24                                    La vita è bella  (1997)     8.6\n",
       "25                                              Se7en  (1995)     8.6\n",
       "26                           The Silence of the Lambs  (1991)     8.6\n",
       "27                                          Star Wars  (1977)     8.6\n",
       "28                                            Seppuku  (1962)     8.6\n",
       "29                               Shichinin no samurai  (1954)     8.6\n",
       "30                              It's a Wonderful Life  (1946)     8.6\n",
       "31                                           Whiplash  (2014)     8.5\n",
       "32                                   The Intouchables  (2011)     8.5\n",
       "33                                       The Prestige  (2006)     8.5\n",
       "34                                       The Departed  (2006)     8.5\n",
       "35                                        The Pianist  (2002)     8.5\n",
       "36                                          Gladiator  (2000)     8.5\n",
       "37                                 American History X  (1998)     8.5\n",
       "38                                 The Usual Suspects  (1995)     8.5\n",
       "39                                               Léon  (1994)     8.5\n",
       "40                                      The Lion King  (1994)     8.5\n",
       "41                         Terminator 2: Judgment Day  (1991)     8.5\n",
       "42                              Nuovo Cinema Paradiso  (1988)     8.5\n",
       "43                                     Hotaru no haka  (1988)     8.5\n",
       "44                                 Back to the Future  (1985)     8.5\n",
       "45                       Once Upon a Time in the West  (1968)     8.5\n",
       "46                                             Psycho  (1960)     8.5\n",
       "47                                        Rear Window  (1954)     8.5\n",
       "48                                         Casablanca  (1942)     8.5\n",
       "49                                       Modern Times  (1936)     8.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IMDB’s Top rated 100 movies#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "page = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc')\n",
    "soup = BeautifulSoup(page.content)\n",
    "movie_name = []\n",
    "movie_name = soup.find_all('h3',class_=\"lister-item-header\")\n",
    "movie_name\n",
    "\n",
    "movies = []\n",
    "for movie in movie_name:\n",
    "    movie = movie.get_text().split('\\n')[2]\n",
    "    movies.append(movie)\n",
    "movies\n",
    "\n",
    "year_release = []\n",
    "year_release = soup.find_all('span', class_=\"lister-item-year text-muted unbold\")\n",
    "year_release\n",
    "\n",
    "year = []\n",
    "for year_of_release in year_release:\n",
    "    year_of_release = year_of_release.get_text().replace('\\n','')\n",
    "    year.append(year_of_release)\n",
    "year\n",
    "    \n",
    "ratings_scraped = []\n",
    "ratings_scraped = soup.find_all('div', class_=\"inline-block ratings-imdb-rating\")\n",
    "ratings_scraped\n",
    "\n",
    "ratings = []\n",
    "for rating in ratings_scraped:\n",
    "    rating = rating.get_text().split('\\n')[2]\n",
    "    ratings.append(rating)\n",
    "ratings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'movies':movies,'year':year,'ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "221bad6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movies</th>\n",
       "      <th>year</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>(2021)</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C/o Kancharapalem</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>C U Soon</td>\n",
       "      <td>(2020)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Aamir</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Earth</td>\n",
       "      <td>(1998)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Detective Byomkesh Bakshy!</td>\n",
       "      <td>(2015)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Madras Cafe</td>\n",
       "      <td>(2013)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               movies    year ratings\n",
       "0                            Jai Bhim  (2021)     8.6\n",
       "1                             Nayakan  (1987)     8.5\n",
       "2                   Pariyerum Perumal  (2018)     8.5\n",
       "3                          Anbe Sivam  (2003)     8.5\n",
       "4                   C/o Kancharapalem  (2018)     8.5\n",
       "..                                ...     ...     ...\n",
       "245                          C U Soon  (2020)     7.6\n",
       "246                             Aamir  (2008)     7.6\n",
       "247                             Earth  (1998)     7.6\n",
       "248        Detective Byomkesh Bakshy!  (2015)     7.6\n",
       "249                       Madras Cafe  (2013)     7.6\n",
       "\n",
       "[250 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " ##IMDB’s Top rated 100 indian movies\n",
    "\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "soup = BeautifulSoup(page.content)\n",
    "movie_name = []\n",
    "movie_name = soup.find_all('td' ,class_=\"titleColumn\")\n",
    "movie_name\n",
    "\n",
    "movies = []\n",
    "for movie in movie_name:\n",
    "    movie = movie.get_text().split('\\n')[2]\n",
    "    movies.append(movie)\n",
    "movies\n",
    "\n",
    "year_release = []\n",
    "year_release = soup.find_all('span', class_=\"secondaryInfo\")\n",
    "year_release\n",
    "\n",
    "year = []\n",
    "for year_of_release in year_release:\n",
    "    year_of_release = year_of_release.get_text().replace('\\n','')\n",
    "    year.append(year_of_release)\n",
    "year\n",
    "    \n",
    "ratings_scraped = []\n",
    "ratings_scraped = soup.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "ratings_scraped\n",
    "\n",
    "ratings = []\n",
    "for rating in ratings_scraped:\n",
    "    rating = rating.get_text().split('\\n')[1]\n",
    "    ratings.append(rating)\n",
    "ratings\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'movies':movies,'year':year,'ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4ab6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,793]</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[3,244]</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,624]</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[2,459]</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[2,524]</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,740]</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,523]</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[2,657]</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[1,054]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches   points                          ratings\n",
       "0   New Zealand      17    2,054                              121\n",
       "1       England    [32]  [3,793]                              119\n",
       "2     Australia    [28]  [3,244]                              116\n",
       "3         India    [32]  [3,624]                              113\n",
       "4  South Africa    [25]  [2,459]                               98\n",
       "5      Pakistan    [27]  [2,524]                               93\n",
       "6    Bangladesh    [30]  [2,740]                               91\n",
       "7   West Indies    [30]  [2,523]                               84\n",
       "8     Sri Lanka    [32]  [2,657]                               83\n",
       "9   Afghanistan    [17]  [1,054]                               62"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI teams in men’s cricket\n",
    "\n",
    "\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')[0]\n",
    "    ab.append(abc)\n",
    "ab\n",
    "team_name=ab[0:10]\n",
    "\n",
    "\n",
    "team_name#imp\n",
    "\n",
    "\n",
    "matches = []\n",
    "matches = soup.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "matches\n",
    "\n",
    "a_match = []\n",
    "for a_c in matches:\n",
    "    a_c = a_c.get_text().split('\\n')[0]\n",
    "    a_match.append(a_c)\n",
    "    \n",
    "a_match\n",
    "\n",
    "a_matches = []\n",
    "a_matches = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "a_matches\n",
    "\n",
    "ab_match = []\n",
    "for a_m in a_matches:\n",
    "    a_m = a_m.get_text().split('\\n')\n",
    "    ab_match.append(a_m)\n",
    "    \n",
    "ab_match\n",
    "\n",
    "point = []\n",
    "team_point = []\n",
    "team_point = soup.find_all('td',class_=\"rankings-block__banner--points\" )\n",
    "team_point\n",
    "\n",
    "for r in team_point:\n",
    "    r = r.get_text().split('\\n')[0]\n",
    "point.append(r)  \n",
    "    \n",
    "point\n",
    "\n",
    "matche_played = ab_match[::2]\n",
    "\n",
    "matche_played\n",
    "\n",
    "matches_played = a_match + matche_played\n",
    "\n",
    "matches_played  \n",
    "m=matches_played[0:10]  \n",
    "\n",
    "m\n",
    "\n",
    "points = ab_match[1::2]\n",
    "points\n",
    "team_points = point + points\n",
    "\n",
    "\n",
    "team_points\n",
    "\n",
    "t = team_points[0:10] \n",
    "\n",
    "t\n",
    "\n",
    "rating = []\n",
    "team_rating = []\n",
    "team_rating = soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\" )\n",
    "team_rating\n",
    "\n",
    "for r in team_rating:\n",
    "    r = r.get_text().split('\\n')[1]\n",
    "    rating.append(r)    \n",
    "rating\n",
    "\n",
    "\n",
    "\n",
    "team_ratings = []\n",
    "team_ratings = soup.find_all('td',class_=\"table-body__cell u-text-right rating\" )\n",
    "team_ratings\n",
    "\n",
    "for ra in team_ratings:\n",
    "    ra = ra.get_text().split('\\n')[0]\n",
    "    rating.append(ra)\n",
    "\n",
    "    \n",
    "rating\n",
    "ratings=rating[0:10]\n",
    "ratings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'team':team_name,'matches':m ,'points':t,'ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d65d5a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,793]</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>[28]</td>\n",
       "      <td>[3,244]</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[3,624]</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[2,459]</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>[27]</td>\n",
       "      <td>[2,524]</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,740]</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>[30]</td>\n",
       "      <td>[2,523]</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>[32]</td>\n",
       "      <td>[2,657]</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[1,054]</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches   points                          ratings\n",
       "0   New Zealand      17    2,054                              121\n",
       "1       England    [32]  [3,793]                              119\n",
       "2     Australia    [28]  [3,244]                              116\n",
       "3         India    [32]  [3,624]                              113\n",
       "4  South Africa    [25]  [2,459]                               98\n",
       "5      Pakistan    [27]  [2,524]                               93\n",
       "6    Bangladesh    [30]  [2,740]                               91\n",
       "7   West Indies    [30]  [2,523]                               84\n",
       "8     Sri Lanka    [32]  [2,657]                               83\n",
       "9   Afghanistan    [17]  [1,054]                               62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Top 10 ODI teams in men’s cricket\n",
    "\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')[0]\n",
    "    ab.append(abc)\n",
    "ab\n",
    "team_name=ab[0:10]\n",
    "\n",
    "\n",
    "team_name#imp\n",
    "\n",
    "\n",
    "matches = []\n",
    "matches = soup.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "matches\n",
    "\n",
    "a_match = []\n",
    "for a_c in matches:\n",
    "    a_c = a_c.get_text().split('\\n')[0]\n",
    "    a_match.append(a_c)\n",
    "    \n",
    "a_match\n",
    "\n",
    "a_matches = []\n",
    "a_matches = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "a_matches\n",
    "\n",
    "ab_match = []\n",
    "for a_m in a_matches:\n",
    "    a_m = a_m.get_text().split('\\n')\n",
    "    ab_match.append(a_m)\n",
    "    \n",
    "ab_match\n",
    "\n",
    "point = []\n",
    "team_point = []\n",
    "team_point = soup.find_all('td',class_=\"rankings-block__banner--points\" )\n",
    "team_point\n",
    "\n",
    "for r in team_point:\n",
    "    r = r.get_text().split('\\n')[0]\n",
    "point.append(r)  \n",
    "    \n",
    "point\n",
    "\n",
    "matche_played = ab_match[::2]\n",
    "\n",
    "matche_played\n",
    "\n",
    "matches_played = a_match + matche_played\n",
    "\n",
    "matches_played  \n",
    "m=matches_played[0:10]  \n",
    "\n",
    "m\n",
    "\n",
    "points = ab_match[1::2]\n",
    "points\n",
    "team_points = point + points\n",
    "\n",
    "\n",
    "team_points\n",
    "\n",
    "t = team_points[0:10] \n",
    "\n",
    "t\n",
    "\n",
    "rating = []\n",
    "team_rating = []\n",
    "team_rating = soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\" )\n",
    "team_rating\n",
    "\n",
    "for r in team_rating:\n",
    "    r = r.get_text().split('\\n')[1]\n",
    "    rating.append(r)    \n",
    "rating\n",
    "\n",
    "\n",
    "\n",
    "team_ratings = []\n",
    "team_ratings = soup.find_all('td',class_=\"table-body__cell u-text-right rating\" )\n",
    "team_ratings\n",
    "\n",
    "for ra in team_ratings:\n",
    "    ra = ra.get_text().split('\\n')[0]\n",
    "    rating.append(ra)\n",
    "\n",
    "    \n",
    "rating\n",
    "ratings=rating[0:10]\n",
    "ratings\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'team':team_name,'matches':m ,'points':t,'ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95484ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>[873]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>[844]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>[813]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[779]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[775]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[762]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>[758]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>[743]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name country rating\n",
       "0       Babar Azam     PAK  [873]\n",
       "1      Virat Kohli     IND  [844]\n",
       "2     Rohit Sharma     IND  [813]\n",
       "3      Ross Taylor      NZ  [801]\n",
       "4      Aaron Finch     AUS  [779]\n",
       "5   Jonny Bairstow     ENG  [775]\n",
       "6     David Warner     AUS  [762]\n",
       "7        Shai Hope      WI  [758]\n",
       "8  Kane Williamson      NZ  [754]\n",
       "9  Quinton de Kock      SA  [743]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 ODI Batsmen in men\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "a_pname = []\n",
    "a_pname = soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "a_pname\n",
    "\n",
    "a = []\n",
    "for ab in a_pname:\n",
    "    ab = ab.get_text().split('\\n')\n",
    "    a.append(ab)\n",
    "name=[]    \n",
    "name=a[0]\n",
    "name\n",
    "\n",
    "\n",
    "ab_pname = []\n",
    "ab_pname = soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "ab_pname\n",
    "\n",
    "b = []\n",
    "for abc in ab_pname:\n",
    "    abc = abc.get_text().split('\\n')[1]\n",
    "    b.append(abc)\n",
    "    \n",
    "b\n",
    "\n",
    "bx=b[0:9]\n",
    "bx\n",
    "p = name + bx\n",
    "\n",
    "p      ####imp\n",
    "\n",
    "\n",
    "\n",
    "country = []\n",
    "country = soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "country\n",
    "\n",
    "a_country = []\n",
    "for a_c in country:\n",
    "    a_c = a_c.get_text().split('\\n')[2]\n",
    "    a_country.append(a_c)\n",
    "    \n",
    "a_country\n",
    "\n",
    "team = a_country[0:1]\n",
    "\n",
    "team\n",
    "\n",
    "bcountry = []\n",
    "bcountry = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "bcountry\n",
    "\n",
    "d = []\n",
    "for xy in bcountry:\n",
    "    xy = xy.get_text().split('\\n')[0]\n",
    "    d.append(xy)\n",
    "    \n",
    "d\n",
    "count=d[0:9]\n",
    "\n",
    "count\n",
    "tn= team+count\n",
    "tn\n",
    "\n",
    "\n",
    "\n",
    "tn       #imp\n",
    "\n",
    "\n",
    "rating = []\n",
    "rating = soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "rating\n",
    "\n",
    "a_rating = []\n",
    "for a_r in rating:\n",
    "    a_r = a_r.get_text().split('\\n')\n",
    "    a_rating.append(a_r)\n",
    "    \n",
    "a_rating\n",
    "ar_rating = a_rating[0:1]\n",
    "ar_rating\n",
    "\n",
    "\n",
    "brating = []\n",
    "brating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "brating\n",
    "\n",
    "firstr = []\n",
    "b_rating = []\n",
    "for b_r in brating:\n",
    "    b_r = b_r.get_text().split('\\n')\n",
    "    firstr.append(b_r)\n",
    "    \n",
    "firstr\n",
    "f_rating = firstr[0:9]\n",
    "\n",
    "f_rating\n",
    "\n",
    "r=ar_rating + f_rating\n",
    "r#imp\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'name':p,'country':tn,'rating':r})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da3b417d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[737]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[709]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>[708]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[700]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>[692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[691]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>[679]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[652]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>[650]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>[643]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name country rating\n",
       "0       Trent Boult      NZ  [737]\n",
       "1    Josh Hazlewood     AUS  [709]\n",
       "2  Mujeeb Ur Rahman     AFG  [708]\n",
       "3      Chris Woakes     ENG  [700]\n",
       "4      Mehedi Hasan     BAN  [692]\n",
       "5        Matt Henry      NZ  [691]\n",
       "6    Jasprit Bumrah     IND  [679]\n",
       "7    Mitchell Starc     AUS  [652]\n",
       "8   Shakib Al Hasan     BAN  [650]\n",
       "9     Kagiso Rabada      SA  [643]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI bowlers along men\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "a_pname = []\n",
    "a_pname = soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "a_pname\n",
    "\n",
    "a = []\n",
    "for ab in a_pname:\n",
    "    ab = ab.get_text().split('\\n')\n",
    "    a.append(ab)\n",
    "name=[]    \n",
    "name=a[1]\n",
    "name\n",
    "\n",
    "\n",
    "ab_pname = []\n",
    "ab_pname = soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "ab_pname\n",
    "\n",
    "b = []\n",
    "for abc in ab_pname:\n",
    "    abc = abc.get_text().split('\\n')[1]\n",
    "    b.append(abc)\n",
    "    \n",
    "b\n",
    "\n",
    "bx=b[9:18]\n",
    "bx\n",
    "p = name + bx\n",
    "\n",
    "p  #imp\n",
    "\n",
    "\n",
    "\n",
    "country = []\n",
    "country = soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "country\n",
    "\n",
    "a_country = []\n",
    "for a_c in country:\n",
    "    a_c = a_c.get_text().split('\\n')[2]\n",
    "    a_country.append(a_c)\n",
    "    \n",
    "a_country\n",
    "\n",
    "team = a_country[1:2]\n",
    "\n",
    "team\n",
    "\n",
    "bcountry = []\n",
    "bcountry = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "bcountry\n",
    "\n",
    "d = []\n",
    "for xy in bcountry:\n",
    "    xy = xy.get_text().split('\\n')[0]\n",
    "    d.append(xy)\n",
    "    \n",
    "d\n",
    "count=d[9:18]\n",
    "\n",
    "count\n",
    "tn= team+count\n",
    "\n",
    "\n",
    "tn#####imp\n",
    "\n",
    "rating = []\n",
    "rating = soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "rating\n",
    "\n",
    "a_rating = []\n",
    "for a_r in rating:\n",
    "    a_r = a_r.get_text().split('\\n')\n",
    "    a_rating.append(a_r)\n",
    "    \n",
    "a_rating\n",
    "ar_rating = a_rating[1:2]\n",
    "ar_rating\n",
    "\n",
    "\n",
    "brating = []\n",
    "brating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "brating\n",
    "\n",
    "firstr = []\n",
    "b_rating = []\n",
    "for b_r in brating:\n",
    "    b_r = b_r.get_text().split('\\n')\n",
    "    firstr.append(b_r)\n",
    "    \n",
    "firstr\n",
    "f_rating = firstr[9:18]\n",
    "\n",
    "f_rating\n",
    "\n",
    "r=ar_rating + f_rating\n",
    "r#imp\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'name':p,'country':tn,'rating':r})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0593e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>17</td>\n",
       "      <td>2,746</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[2,307]</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[2,148]</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[1,899]</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[475]</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[1,668]</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>[19]</td>\n",
       "      <td>[1,658]</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[1,226]</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[240]</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>[5]</td>\n",
       "      <td>[233]</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           team matches   points                          ratings\n",
       "0     Australia      17    2,746                              162\n",
       "1  South Africa    [19]  [2,307]                              121\n",
       "2       England    [18]  [2,148]                              119\n",
       "3         India    [17]  [1,899]                              112\n",
       "4    Bangladesh     [5]    [475]                               95\n",
       "5   New Zealand    [19]  [1,668]                               88\n",
       "6   West Indies    [19]  [1,658]                               87\n",
       "7      Pakistan    [18]  [1,226]                               68\n",
       "8       Ireland     [5]    [240]                               48\n",
       "9     Sri Lanka     [5]    [233]                               47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 ODI teams in women’s\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('span', class_=\"u-hide-phablet\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')[0]\n",
    "    ab.append(abc)\n",
    "    \n",
    "team_name = ab[0:10]\n",
    "\n",
    "team_name  #imp\n",
    "\n",
    "matches = []\n",
    "matches = soup.find_all('td', class_=\"rankings-block__banner--matches\")\n",
    "matches\n",
    "\n",
    "a_match = []\n",
    "for a_c in matches:\n",
    "    a_c = a_c.get_text().split('\\n')[0]\n",
    "    a_match.append(a_c)\n",
    "    \n",
    "a_match\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a_matches = []\n",
    "a_matches = soup.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "a_matches\n",
    "\n",
    "ab_match = []\n",
    "for a_m in a_matches:\n",
    "    a_m = a_m.get_text().split('\\n')\n",
    "    ab_match.append(a_m)\n",
    "    \n",
    "ab_match\n",
    "\n",
    "point = []\n",
    "team_point = []\n",
    "team_point = soup.find_all('td',class_=\"rankings-block__banner--points\" )\n",
    "team_point\n",
    "\n",
    "for r in team_point:\n",
    "    r = r.get_text().split('\\n')[0]\n",
    "point.append(r)  \n",
    "    \n",
    "point\n",
    "\n",
    "matche_played = ab_match[::2]\n",
    "\n",
    "matche_played\n",
    "\n",
    "matches_played = a_match + matche_played\n",
    "\n",
    "matches_played  \n",
    "m=matches_played[0:10]  \n",
    "\n",
    "m#imp\n",
    "\n",
    "points = ab_match[1::2]\n",
    "points\n",
    "team_points = point + points\n",
    "\n",
    "\n",
    "team_points\n",
    "\n",
    "t = team_points[0:10] \n",
    "\n",
    "t\n",
    "\n",
    "\n",
    "m\n",
    "rating = []\n",
    "team_rating = []\n",
    "team_rating = soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\" )\n",
    "team_rating\n",
    "\n",
    "for r in team_rating:\n",
    "    r = r.get_text().split('\\n')[1]\n",
    "    rating.append(r)    \n",
    "rating\n",
    "\n",
    "\n",
    "\n",
    "team_ratings = []\n",
    "team_ratings = soup.find_all('td',class_=\"table-body__cell u-text-right rating\" )\n",
    "team_ratings\n",
    "\n",
    "for ra in team_ratings:\n",
    "    ra = ra.get_text().split('\\n')[0]\n",
    "    rating.append(ra)\n",
    "\n",
    "    \n",
    "rating\n",
    "ratings=rating[0:10]\n",
    "ratings\n",
    "\n",
    "#imp\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'team':team_name,'matches':m ,'points':t,'ratings':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a9b4d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>[761]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[750]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>[738]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[728]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>[717]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>[710]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[699]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[690]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>[676]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heather Knight</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[674]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name country rating\n",
       "0        Lizelle Lee      SA  [761]\n",
       "1       Alyssa Healy     AUS  [750]\n",
       "2        Mithali Raj     IND  [738]\n",
       "3     Tammy Beaumont     ENG  [728]\n",
       "4  Amy Satterthwaite      NZ  [717]\n",
       "5    Smriti Mandhana     IND  [710]\n",
       "6        Meg Lanning     AUS  [699]\n",
       "7        Beth Mooney     AUS  [690]\n",
       "8    Stafanie Taylor      WI  [676]\n",
       "9     Heather Knight     ENG  [674]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 women’s ODI Batsmen\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "a_pname = []\n",
    "a_pname = soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "a_pname\n",
    "\n",
    "a = []\n",
    "for ab in a_pname:\n",
    "    ab = ab.get_text().split('\\n')[0]\n",
    "    a.append(ab)\n",
    "name=[]    \n",
    "name=a[0:1]\n",
    "name\n",
    "\n",
    "ab_pname = []\n",
    "ab_pname = soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "ab_pname\n",
    "\n",
    "b = []\n",
    "for abc in ab_pname:\n",
    "    abc = abc.get_text().split('\\n')[1]\n",
    "    b.append(abc)\n",
    "    \n",
    "b\n",
    "bx=b[0:9]\n",
    "bx\n",
    "p = name + bx\n",
    "p\n",
    "\n",
    "\n",
    "country = []\n",
    "country = soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "country\n",
    "\n",
    "a_country = []\n",
    "for a_c in country:\n",
    "    a_c = a_c.get_text().split('\\n')[2]\n",
    "    a_country.append(a_c)\n",
    "    \n",
    "a_country\n",
    "\n",
    "team = a_country[0:1]\n",
    "\n",
    "team\n",
    "\n",
    "bcountry = []\n",
    "bcountry = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "bcountry\n",
    "\n",
    "d = []\n",
    "for xy in bcountry:\n",
    "    xy = xy.get_text().split('\\n')[0]\n",
    "    d.append(xy)\n",
    "    \n",
    "d\n",
    "count=d[0:9]\n",
    "\n",
    "count\n",
    "tn= team+count\n",
    "tn\n",
    "\n",
    "\n",
    "\n",
    "tn       #imp\n",
    "\n",
    "\n",
    "rating = []\n",
    "rating = soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "rating\n",
    "\n",
    "a_rating = []\n",
    "for a_r in rating:\n",
    "    a_r = a_r.get_text().split('\\n')\n",
    "    a_rating.append(a_r)\n",
    "    \n",
    "a_rating\n",
    "ar_rating = a_rating[0:1]\n",
    "ar_rating\n",
    "\n",
    "\n",
    "brating = []\n",
    "brating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "brating\n",
    "\n",
    "firstr = []\n",
    "b_rating = []\n",
    "for b_r in brating:\n",
    "    b_r = b_r.get_text().split('\\n')\n",
    "    firstr.append(b_r)\n",
    "    \n",
    "firstr\n",
    "f_rating = firstr[0:9]\n",
    "\n",
    "f_rating\n",
    "\n",
    "r=ar_rating + f_rating\n",
    "r#imp\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'name':p,'country':tn,'rating':r})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5b12c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>[384]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[372]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[365]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>[319]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>[299]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[275]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>[274]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>[272]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name country rating\n",
       "0    Marizanne Kapp      SA  [384]\n",
       "1    Natalie Sciver     ENG  [372]\n",
       "2      Ellyse Perry     AUS  [365]\n",
       "3   Stafanie Taylor      WI  [319]\n",
       "4     Deepti Sharma     IND  [299]\n",
       "5  Ashleigh Gardner     AUS  [275]\n",
       "6  Dane van Niekerk      SA  [274]\n",
       "7   Hayley Matthews      WI  [272]\n",
       "8     Jess Jonassen     AUS  [272]\n",
       "9   Katherine Brunt     ENG  [272]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Top 10 women’s ODI all-rounder\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "a_pname = []\n",
    "a_pname = soup.find_all('div', class_=\"rankings-block__banner--name\")\n",
    "a_pname\n",
    "\n",
    "a = []\n",
    "for ab in a_pname:\n",
    "    ab = ab.get_text().split('\\n')[0]\n",
    "    a.append(ab)\n",
    "name=[]    \n",
    "name=a[2]\n",
    "name\n",
    "\n",
    "#\n",
    "ab_pname = []\n",
    "ab_pname = soup.find_all('td' ,class_=\"table-body__cell name\")\n",
    "ab_pname\n",
    "\n",
    "b = []\n",
    "for abc in ab_pname:\n",
    "    abc = abc.get_text().split('\\n')[1]\n",
    "    b.append(abc)\n",
    "    \n",
    "b\n",
    "bx=b[18:27]\n",
    "bx\n",
    "p = a + bx\n",
    "\n",
    "p.remove('Lizelle Lee')\n",
    "p.remove('Jess Jonassen')\n",
    "\n",
    "p#imp\n",
    "\n",
    "\n",
    "country = []\n",
    "country = soup.find_all('div', class_=\"rankings-block__banner--nationality\")\n",
    "country\n",
    "\n",
    "a_country = []\n",
    "for a_c in country:\n",
    "    a_c = a_c.get_text().split('\\n')[2]\n",
    "    a_country.append(a_c)\n",
    "    \n",
    "a_country\n",
    "\n",
    "\n",
    "\n",
    "bcountry = []\n",
    "bcountry = soup.find_all('span', class_=\"table-body__logo-text\")\n",
    "bcountry\n",
    "\n",
    "d = []\n",
    "for xy in bcountry:\n",
    "    xy = xy.get_text().split('\\n')[0]\n",
    "    d.append(xy)\n",
    "    \n",
    "d\n",
    "count=d[18:27]\n",
    "\n",
    "count\n",
    "tn= a_country+count\n",
    "tn\n",
    "tn.pop(0)\n",
    "tn.pop(0)\n",
    "\n",
    "\n",
    "\n",
    "tn#imp\n",
    "rating = []\n",
    "rating = soup.find_all('div', class_=\"rankings-block__banner--rating\")\n",
    "rating\n",
    "\n",
    "a_rating = []\n",
    "for a_r in rating:\n",
    "    a_r = a_r.get_text().split('\\n')\n",
    "    a_rating.append(a_r)\n",
    "    \n",
    "a_rating\n",
    "ar_rating = a_rating[2]\n",
    "ar_rating\n",
    "\n",
    "\n",
    "brating = []\n",
    "brating = soup.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    "brating\n",
    "\n",
    "firstr = []\n",
    "b_rating = []\n",
    "for b_r in brating:\n",
    "    b_r = b_r.get_text().split('\\n')\n",
    "    firstr.append(b_r)\n",
    "    \n",
    "firstr\n",
    "f_rating = firstr[18:27]\n",
    "\n",
    "f_rating\n",
    "\n",
    "r=a_rating + f_rating\n",
    "r.pop(0)\n",
    "r.pop(0)\n",
    "\n",
    "\n",
    "r  #imp\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'name':p,'country':tn,'rating':r})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52c2ec2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEADING</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CODE FOR YOUTUBE VEDIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python Tutorial: Zip Files – Creating and Extr...</td>\n",
       "      <td>[November 19, 2019]</td>\n",
       "      <td>[, In this video, we will be learning how to c...</td>\n",
       "      <td>https://www.youtube.com/embed/z0gguhEmWiY?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python Data Science Tutorial: Analyzing the 20...</td>\n",
       "      <td>[October 17, 2019]</td>\n",
       "      <td>[, In this Python Programming video, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/_P7X8tMplsw?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python Multiprocessing Tutorial: Run Code in P...</td>\n",
       "      <td>[September 21, 2019]</td>\n",
       "      <td>[, In this Python Programming video, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/fKl2JW_qrso?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Threading Tutorial: Run Code Concurrent...</td>\n",
       "      <td>[September 12, 2019]</td>\n",
       "      <td>[, In this Python Programming video, we will b...</td>\n",
       "      <td>https://www.youtube.com/embed/IEEhzQoKtQU?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Update (2019-09-03)</td>\n",
       "      <td>[September 3, 2019]</td>\n",
       "      <td>[, Hey everyone. I wanted to give you an updat...</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Python Quick Tip: The Difference Between “==” ...</td>\n",
       "      <td>[August 6, 2019]</td>\n",
       "      <td>[, In this Python Programming Tutorial, we wil...</td>\n",
       "      <td>https://www.youtube.com/embed/mO_dS3rXDIs?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Tutorial: Calling External Commands Usi...</td>\n",
       "      <td>[July 24, 2019]</td>\n",
       "      <td>[, In this Python Programming Tutorial, we wil...</td>\n",
       "      <td>https://www.youtube.com/embed/2Fp1N6dof0Y?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Visual Studio Code (Windows) – Setting up a Py...</td>\n",
       "      <td>[May 1, 2019]</td>\n",
       "      <td>[, In this Python Programming Tutorial, we wil...</td>\n",
       "      <td>https://www.youtube.com/embed/-nh9rCzPJ20?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Visual Studio Code (Mac) – Setting up a Python...</td>\n",
       "      <td>[May 1, 2019]</td>\n",
       "      <td>[, In this Python Programming Tutorial, we wil...</td>\n",
       "      <td>https://www.youtube.com/embed/06I63_p-2A4?vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clarifying the Issues with Mutable Default Arg...</td>\n",
       "      <td>[April 24, 2019]</td>\n",
       "      <td>[, In this Python Programming Tutorial, we wil...</td>\n",
       "      <td>https://www.youtube.com/embed/_JGmemuINww?vers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             HEADING                  DATE  \\\n",
       "0  Python Tutorial: Zip Files – Creating and Extr...   [November 19, 2019]   \n",
       "1  Python Data Science Tutorial: Analyzing the 20...    [October 17, 2019]   \n",
       "2  Python Multiprocessing Tutorial: Run Code in P...  [September 21, 2019]   \n",
       "3  Python Threading Tutorial: Run Code Concurrent...  [September 12, 2019]   \n",
       "4                                Update (2019-09-03)   [September 3, 2019]   \n",
       "5  Python Quick Tip: The Difference Between “==” ...      [August 6, 2019]   \n",
       "6  Python Tutorial: Calling External Commands Usi...       [July 24, 2019]   \n",
       "7  Visual Studio Code (Windows) – Setting up a Py...         [May 1, 2019]   \n",
       "8  Visual Studio Code (Mac) – Setting up a Python...         [May 1, 2019]   \n",
       "9  Clarifying the Issues with Mutable Default Arg...      [April 24, 2019]   \n",
       "\n",
       "                                             CONTENT  \\\n",
       "0  [, In this video, we will be learning how to c...   \n",
       "1  [, In this Python Programming video, we will b...   \n",
       "2  [, In this Python Programming video, we will b...   \n",
       "3  [, In this Python Programming video, we will b...   \n",
       "4  [, Hey everyone. I wanted to give you an updat...   \n",
       "5  [, In this Python Programming Tutorial, we wil...   \n",
       "6  [, In this Python Programming Tutorial, we wil...   \n",
       "7  [, In this Python Programming Tutorial, we wil...   \n",
       "8  [, In this Python Programming Tutorial, we wil...   \n",
       "9  [, In this Python Programming Tutorial, we wil...   \n",
       "\n",
       "                              CODE FOR YOUTUBE VEDIO  \n",
       "0  https://www.youtube.com/embed/z0gguhEmWiY?vers...  \n",
       "1  https://www.youtube.com/embed/_P7X8tMplsw?vers...  \n",
       "2  https://www.youtube.com/embed/fKl2JW_qrso?vers...  \n",
       "3  https://www.youtube.com/embed/IEEhzQoKtQU?vers...  \n",
       "4                                                 NA  \n",
       "5  https://www.youtube.com/embed/mO_dS3rXDIs?vers...  \n",
       "6  https://www.youtube.com/embed/2Fp1N6dof0Y?vers...  \n",
       "7  https://www.youtube.com/embed/-nh9rCzPJ20?vers...  \n",
       "8  https://www.youtube.com/embed/06I63_p-2A4?vers...  \n",
       "9  https://www.youtube.com/embed/_JGmemuINww?vers...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A python program to scrape details of all the posts from coreyms.com.\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://coreyms.com/')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('header', class_=\"entry-header\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')[0]\n",
    "    ab.append(abc)\n",
    "    \n",
    "\n",
    "ab\n",
    "#heading\n",
    "\n",
    "\n",
    "b = []\n",
    "b = soup.find_all('time', class_=\"entry-time\")\n",
    "b\n",
    "\n",
    "bb = []\n",
    "for bbc in b:\n",
    "    bbc = bbc.get_text().split('\\n')\n",
    "    bb.append(bbc)\n",
    "    \n",
    "bb#date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "c = []\n",
    "c = soup.find_all('div', class_=\"entry-content\")\n",
    "c\n",
    "\n",
    "cb = []\n",
    "for cbc in c:\n",
    "    cbc = cbc.get_text().split('\\n')\n",
    "    cb.append(cbc)\n",
    "    \n",
    "cb \n",
    "cb#content\n",
    "\n",
    "\n",
    "\n",
    "d = []\n",
    "d = soup.find_all('iframe', class_=\"youtube-player\")\n",
    "d\n",
    "\n",
    "vedio = []\n",
    "for i in d:\n",
    "    vedio.append(i['src'])\n",
    "    \n",
    "vedio\n",
    "vedio.insert(4,'NA')\n",
    "\n",
    "vedio\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'HEADING':ab,'DATE':bb,'CONTENT':cb,'CODE FOR YOUTUBE VEDIO':vedio})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0c3228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSE TITLE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>AREA</th>\n",
       "      <th>EMI</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3 BHK Flat  For Sale  In Acme Oakwood And Ashw...</td>\n",
       "      <td>[.Khewra circle Near Hirandani Medows]</td>\n",
       "      <td>[1,300 sqft]</td>\n",
       "      <td>[₹1 Lacs/Month]</td>\n",
       "      <td>[₹1.75 Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Tata Glendale In...</td>\n",
       "      <td>[Tata Glendale  Vasant Vihar, Thane West]</td>\n",
       "      <td>[1,323 sqft]</td>\n",
       "      <td>[₹1.58 Lacs/Month]</td>\n",
       "      <td>[₹2.75 Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 BHK Flat  For Sale  In Payal Chs In Thane West</td>\n",
       "      <td>[New Shakti Mill Bus Stop, Near Vikas Palms, D...</td>\n",
       "      <td>[505 sqft]</td>\n",
       "      <td>[₹31,522/Month]</td>\n",
       "      <td>[₹55 Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Lodha Paradise I...</td>\n",
       "      <td>[lodha paradise  Bhiwandi Bypass Road,Near Dou...</td>\n",
       "      <td>[625 sqft]</td>\n",
       "      <td>[₹44,705/Month]</td>\n",
       "      <td>[₹78 Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 BHK Apartment  For Sale  In Lodha Splendora,...</td>\n",
       "      <td>[Lodha Splendora,  Tierra  OPP to puranic city ]</td>\n",
       "      <td>[1,170 sqft]</td>\n",
       "      <td>[₹60,753/Month]</td>\n",
       "      <td>[₹1.06 Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2 BHK Flat  For Sale  In Raymond Ten X Habitat...</td>\n",
       "      <td>[Gokhale Rd,]</td>\n",
       "      <td>[669 sqft]</td>\n",
       "      <td>[₹65,338/Month]</td>\n",
       "      <td>[₹1.14 Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1 BHK Flat  For Sale  In Raymond Realty Tenx I...</td>\n",
       "      <td>[Jekegram Pokharan Rd Number 1, Thane, ]</td>\n",
       "      <td>[566 sqft]</td>\n",
       "      <td>[₹50,459/Month]</td>\n",
       "      <td>[₹88.04 Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1 BHK Flat  For Sale  In Hiranandani Srushti C...</td>\n",
       "      <td>[ Shrusti-3, Hiranandani Estate, Thane West, T...</td>\n",
       "      <td>[640 sqft]</td>\n",
       "      <td>[₹37,254/Month]</td>\n",
       "      <td>[₹65 Lacs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Kalpataru Hills ...</td>\n",
       "      <td>[Kalpataru Hills   Tikuji Ni Wadi Rd, Hill Gar...</td>\n",
       "      <td>[690 sqft]</td>\n",
       "      <td>[₹68,777/Month]</td>\n",
       "      <td>[₹1.2 Crores]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2 BHK Apartment  For Sale  In Lodha Paradise C...</td>\n",
       "      <td>[Lodha paradise CHS  Opp Lodha World school Ne...</td>\n",
       "      <td>[1,100 sqft]</td>\n",
       "      <td>[₹69,350/Month]</td>\n",
       "      <td>[₹1.21 Crores]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         HOUSE TITLE  \\\n",
       "0  3 BHK Flat  For Sale  In Acme Oakwood And Ashw...   \n",
       "1  3 BHK Apartment  For Sale  In Tata Glendale In...   \n",
       "2  1 BHK Flat  For Sale  In Payal Chs In Thane West    \n",
       "3  2 BHK Apartment  For Sale  In Lodha Paradise I...   \n",
       "4  3 BHK Apartment  For Sale  In Lodha Splendora,...   \n",
       "5  2 BHK Flat  For Sale  In Raymond Ten X Habitat...   \n",
       "6  1 BHK Flat  For Sale  In Raymond Realty Tenx I...   \n",
       "7  1 BHK Flat  For Sale  In Hiranandani Srushti C...   \n",
       "8  2 BHK Apartment  For Sale  In Kalpataru Hills ...   \n",
       "9  2 BHK Apartment  For Sale  In Lodha Paradise C...   \n",
       "\n",
       "                                            LOCATION          AREA  \\\n",
       "0             [.Khewra circle Near Hirandani Medows]  [1,300 sqft]   \n",
       "1          [Tata Glendale  Vasant Vihar, Thane West]  [1,323 sqft]   \n",
       "2  [New Shakti Mill Bus Stop, Near Vikas Palms, D...    [505 sqft]   \n",
       "3  [lodha paradise  Bhiwandi Bypass Road,Near Dou...    [625 sqft]   \n",
       "4   [Lodha Splendora,  Tierra  OPP to puranic city ]  [1,170 sqft]   \n",
       "5                                      [Gokhale Rd,]    [669 sqft]   \n",
       "6           [Jekegram Pokharan Rd Number 1, Thane, ]    [566 sqft]   \n",
       "7  [ Shrusti-3, Hiranandani Estate, Thane West, T...    [640 sqft]   \n",
       "8  [Kalpataru Hills   Tikuji Ni Wadi Rd, Hill Gar...    [690 sqft]   \n",
       "9  [Lodha paradise CHS  Opp Lodha World school Ne...  [1,100 sqft]   \n",
       "\n",
       "                  EMI           PRICE  \n",
       "0     [₹1 Lacs/Month]  [₹1.75 Crores]  \n",
       "1  [₹1.58 Lacs/Month]  [₹2.75 Crores]  \n",
       "2     [₹31,522/Month]      [₹55 Lacs]  \n",
       "3     [₹44,705/Month]      [₹78 Lacs]  \n",
       "4     [₹60,753/Month]  [₹1.06 Crores]  \n",
       "5     [₹65,338/Month]  [₹1.14 Crores]  \n",
       "6     [₹50,459/Month]   [₹88.04 Lacs]  \n",
       "7     [₹37,254/Month]      [₹65 Lacs]  \n",
       "8     [₹68,777/Month]   [₹1.2 Crores]  \n",
       "9     [₹69,350/Month]  [₹1.21 Crores]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a python program to scrape house details from nobroker.in.\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.nobroker.in/property/sale/mumbai/Thane%20West?searchParam=W3sibGF0IjoxOS4yNDY3MjE4LCJsb24iOjcyLjk3NTk3MTMsInBsYWNlSWQiOiJDaElKNjQwYUNCSzU1enNSaWZwc0V5U1kydU0iLCJwbGFjZU5hbWUiOiJUaGFuZSBXZXN0In1d&radius=2.0&city=mumbai&locality=Thane%20West')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('a', class_=\"nb__U5JyW\")\n",
    "a\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')[0]\n",
    "    ab.append(abc)\n",
    "    \n",
    "ab\n",
    "ht = ab[0:10]\n",
    "\n",
    "\n",
    "ht#imp\n",
    "\n",
    "\n",
    "\n",
    "b = []\n",
    "b = soup.find_all('div', class_=\"nb__1EwQz\")\n",
    "b\n",
    "\n",
    "bb = []\n",
    "for bbc in b:\n",
    "    bbc = bbc.get_text().split('\\n')[0:10]\n",
    "    bb.append(bbc)\n",
    "    \n",
    "bb\n",
    "l = bb[0:10]\n",
    "l\n",
    "\n",
    "d = []\n",
    "d = soup.find_all('div' ,class_=\"font-semi-bold heading-6\")\n",
    "d\n",
    "\n",
    "db = []\n",
    "for dbc in d:\n",
    "    dbc = dbc.get_text().split('\\n')\n",
    "    db.append(dbc)\n",
    "    \n",
    "db\n",
    "area = db[::3]\n",
    "a = area[0:10]\n",
    "\n",
    "emi = db[1::3]\n",
    "e = emi[0:10]\n",
    "\n",
    "price = db[2::3]\n",
    "p = price[0:10]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'HOUSE TITLE':ht,'LOCATION':l,'AREA':a,'EMI':e,'PRICE':p})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "186c7f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurant name</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>location</th>\n",
       "      <th>rating</th>\n",
       "      <th>image url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Castle BarbequeConnaught Place, Central Delhi]</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>[Connaught Place, Central Delhi]</td>\n",
       "      <td>[3.5]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sou...</td>\n",
       "      <td>North Indian, Barbecue, Italian, Asian</td>\n",
       "      <td>[3CS Mall,Lajpat Nagar - 3, South Delhi]</td>\n",
       "      <td>[3.9]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Castle BarbequePacific Mall,Tagore Garden, We...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>[Pacific Mall,Tagore Garden, West Delhi]</td>\n",
       "      <td>[4]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Cafe KnoshThe Leela Ambience Convention Hotel...</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>[The Leela Ambience Convention Hotel,Shahdara,...</td>\n",
       "      <td>[4.3]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The Barbeque CompanyGardens Galleria,Sector 3...</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>[Gardens Galleria,Sector 38A, Noida]</td>\n",
       "      <td>[4.1]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[India GrillHilton Garden Inn,Saket, South Delhi]</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>[Hilton Garden Inn,Saket, South Delhi]</td>\n",
       "      <td>[3.9]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Delhi BarbequeTaurus Sarovar Portico,Mahipalp...</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>[Taurus Sarovar Portico,Mahipalpur, South Delhi]</td>\n",
       "      <td>[3.6]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[The Monarch - Bar Be Que VillageIndirapuram H...</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>[Indirapuram Habitat Centre,Indirapuram, Ghazi...</td>\n",
       "      <td>[3.9]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[World CafeVibe by The Lalit Traveller,Sector ...</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>[Vibe by The Lalit Traveller,Sector 35, Farida...</td>\n",
       "      <td>[4.2]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Indian Grill RoomSuncity Business Tower,Golf ...</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>[Suncity Business Tower,Golf Course Road, Gurg...</td>\n",
       "      <td>[4.3]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[Mad 4 Bar B QueSector 29, Faridabad]</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>[Sector 29, Faridabad]</td>\n",
       "      <td>[3.9]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[Barbeque 29NIT, Faridabad]</td>\n",
       "      <td>North Indian, Chinese, Barbecue</td>\n",
       "      <td>[NIT, Faridabad]</td>\n",
       "      <td>[4.2]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[GlasshouseDoubleTree By Hilton Gurugram Baani...</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>[DoubleTree By Hilton Gurugram Baani Square,Se...</td>\n",
       "      <td>[4.1]</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      restaurant name  \\\n",
       "0     [Castle BarbequeConnaught Place, Central Delhi]   \n",
       "1   [Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sou...   \n",
       "2   [Castle BarbequePacific Mall,Tagore Garden, We...   \n",
       "3   [Cafe KnoshThe Leela Ambience Convention Hotel...   \n",
       "4   [The Barbeque CompanyGardens Galleria,Sector 3...   \n",
       "5   [India GrillHilton Garden Inn,Saket, South Delhi]   \n",
       "6   [Delhi BarbequeTaurus Sarovar Portico,Mahipalp...   \n",
       "7   [The Monarch - Bar Be Que VillageIndirapuram H...   \n",
       "8   [World CafeVibe by The Lalit Traveller,Sector ...   \n",
       "9   [Indian Grill RoomSuncity Business Tower,Golf ...   \n",
       "10              [Mad 4 Bar B QueSector 29, Faridabad]   \n",
       "11                        [Barbeque 29NIT, Faridabad]   \n",
       "12  [GlasshouseDoubleTree By Hilton Gurugram Baani...   \n",
       "\n",
       "                                              cuisine  \\\n",
       "0                               Chinese, North Indian   \n",
       "1              North Indian, Barbecue, Italian, Asian   \n",
       "2                               North Indian, Chinese   \n",
       "3    Multi-Cuisine, North Indian, Italian, Contine...   \n",
       "4            Barbecue, Chinese, Mughlai, North Indian   \n",
       "5                    North Indian, Italian, Oriental    \n",
       "6                              Barbecue, North Indian   \n",
       "7                    North Indian, Chinese, Fast Food   \n",
       "8                  North Indian, Chinese, Continental   \n",
       "9                     North Indian, Mughlai, Barbecue   \n",
       "10                              North Indian, Mughlai   \n",
       "11                    North Indian, Chinese, Barbecue   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...   \n",
       "\n",
       "                                             location rating  \\\n",
       "0                    [Connaught Place, Central Delhi]  [3.5]   \n",
       "1            [3CS Mall,Lajpat Nagar - 3, South Delhi]  [3.9]   \n",
       "2            [Pacific Mall,Tagore Garden, West Delhi]    [4]   \n",
       "3   [The Leela Ambience Convention Hotel,Shahdara,...  [4.3]   \n",
       "4                [Gardens Galleria,Sector 38A, Noida]  [4.1]   \n",
       "5              [Hilton Garden Inn,Saket, South Delhi]  [3.9]   \n",
       "6    [Taurus Sarovar Portico,Mahipalpur, South Delhi]  [3.6]   \n",
       "7   [Indirapuram Habitat Centre,Indirapuram, Ghazi...  [3.9]   \n",
       "8   [Vibe by The Lalit Traveller,Sector 35, Farida...  [4.2]   \n",
       "9   [Suncity Business Tower,Golf Course Road, Gurg...  [4.3]   \n",
       "10                             [Sector 29, Faridabad]  [3.9]   \n",
       "11                                   [NIT, Faridabad]  [4.2]   \n",
       "12  [DoubleTree By Hilton Gurugram Baani Square,Se...  [4.1]   \n",
       "\n",
       "                                            image url  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a python program to scrape mentioned details from dineout.co.in\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('div', class_=\"restnt-info cursor\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')\n",
    "    ab.append(abc)\n",
    "    \n",
    "ab#name\n",
    "\n",
    "\n",
    "\n",
    "b = []\n",
    "b = soup.find_all('div',class_='restnt-loc ellipsis')\n",
    "b\n",
    "\n",
    "bb = []\n",
    "for bbc in b:\n",
    "    bbc = bbc.get_text().split('\\n')\n",
    "    bb.append(bbc)\n",
    "    \n",
    "bb #location\n",
    "\n",
    "\n",
    "c = []\n",
    "c = soup.find_all('span',class_=\"double-line-ellipsis\")\n",
    "c\n",
    "\n",
    "cb = []\n",
    "for cbc in c:\n",
    "    cbc = cbc.get_text().split('|')[1]\n",
    "    cb.append(cbc)\n",
    "    \n",
    "cb #cuisine\n",
    "\n",
    "d = []\n",
    "d = soup.find_all('img', class_='no-img')\n",
    "d\n",
    "\n",
    "db = []\n",
    "for dbc in d:\n",
    "    db.append(dbc['data-src'])\n",
    "    \n",
    "db#images url\n",
    "\n",
    "\n",
    "e = []\n",
    "e = soup.find_all('div', class_=\"restnt-rating rating-4\")\n",
    "e\n",
    "\n",
    "eb = []\n",
    "for ebc in e:\n",
    "    ebc = ebc.get_text().split('\\n')\n",
    "    eb.append(ebc)\n",
    "    \n",
    "eb#rating\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'restaurant name':ab,'cuisine':cb,'location':bb,'rating':eb,'image url':db})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bcd139f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind</th>\n",
       "      <th>weather condition</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[23°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[50%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[23°C]</td>\n",
       "      <td>[6 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[53%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[23°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[50%]</td>\n",
       "      <td>[1015 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[24°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[47%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[24°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[47%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[24°C]</td>\n",
       "      <td>[9 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[47%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[23°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[53%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[22°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[60%]</td>\n",
       "      <td>[1018 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[22°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[60%]</td>\n",
       "      <td>[1018 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[22°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[60%]</td>\n",
       "      <td>[1019 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[23°C]</td>\n",
       "      <td>[9 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[61%]</td>\n",
       "      <td>[1019 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[21°C]</td>\n",
       "      <td>[9 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[69%]</td>\n",
       "      <td>[1019 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[18°C]</td>\n",
       "      <td>[7 km/h]</td>\n",
       "      <td>[Widespread Fog]</td>\n",
       "      <td>[73%]</td>\n",
       "      <td>[1018 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[82%]</td>\n",
       "      <td>[1018 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[6 km/h]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[88%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[6 km/h]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[88%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[6 km/h]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[88%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1016 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[16°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[94%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[17°C]</td>\n",
       "      <td>[Calm]</td>\n",
       "      <td>[Mist]</td>\n",
       "      <td>[88%]</td>\n",
       "      <td>[1017 hPa]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temperature      wind weather condition humidity    pressure\n",
       "0       [23°C]  [7 km/h]  [Widespread Fog]    [50%]  [1016 hPa]\n",
       "1       [23°C]  [6 km/h]  [Widespread Fog]    [53%]  [1016 hPa]\n",
       "2       [23°C]  [7 km/h]  [Widespread Fog]    [50%]  [1015 hPa]\n",
       "3       [24°C]  [7 km/h]  [Widespread Fog]    [47%]  [1016 hPa]\n",
       "4       [24°C]  [7 km/h]  [Widespread Fog]    [47%]  [1016 hPa]\n",
       "5       [24°C]  [9 km/h]  [Widespread Fog]    [47%]  [1017 hPa]\n",
       "6       [23°C]  [7 km/h]  [Widespread Fog]    [53%]  [1017 hPa]\n",
       "7       [22°C]  [7 km/h]  [Widespread Fog]    [60%]  [1018 hPa]\n",
       "8       [22°C]  [7 km/h]  [Widespread Fog]    [60%]  [1018 hPa]\n",
       "9       [22°C]  [7 km/h]  [Widespread Fog]    [60%]  [1019 hPa]\n",
       "10      [23°C]  [9 km/h]  [Widespread Fog]    [61%]  [1019 hPa]\n",
       "11      [21°C]  [9 km/h]  [Widespread Fog]    [69%]  [1019 hPa]\n",
       "12      [18°C]  [7 km/h]  [Widespread Fog]    [73%]  [1018 hPa]\n",
       "13      [16°C]    [Calm]            [Mist]    [82%]  [1018 hPa]\n",
       "14      [16°C]    [Calm]            [Mist]    [94%]  [1017 hPa]\n",
       "15      [16°C]    [Calm]            [Mist]    [94%]  [1017 hPa]\n",
       "16      [16°C]    [Calm]            [Mist]    [94%]  [1017 hPa]\n",
       "17      [16°C]  [6 km/h]            [Mist]    [88%]  [1017 hPa]\n",
       "18      [16°C]  [6 km/h]            [Mist]    [88%]  [1016 hPa]\n",
       "19      [16°C]  [6 km/h]            [Mist]    [88%]  [1016 hPa]\n",
       "20      [16°C]    [Calm]            [Mist]    [94%]  [1016 hPa]\n",
       "21      [16°C]    [Calm]            [Mist]    [94%]  [1016 hPa]\n",
       "22      [16°C]    [Calm]            [Mist]    [94%]  [1017 hPa]\n",
       "23      [17°C]    [Calm]            [Mist]    [88%]  [1017 hPa]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a python program to scrape weather details for last 24 hours from Tutiempo.net\n",
    "\n",
    "from urllib.request import  urlopen\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "\n",
    "context = ssl._create_unverified_context()\n",
    "res = urlopen(\"https://en.tutiempo.net/delhi.html?data=last-24-hours\",\n",
    "              context=context)\n",
    "soup = BeautifulSoup(res,\"html.parser\")\n",
    "\n",
    "a = []\n",
    "a = soup.find_all('td', class_=\"t Temp\")\n",
    "a\n",
    "\n",
    "ab = []\n",
    "for abc in a:\n",
    "    abc = abc.get_text().split('\\n')\n",
    "    ab.append(abc)\n",
    "    \n",
    "ab \n",
    "t =ab[0:24]  \n",
    "t #temp\n",
    "\n",
    "\n",
    "b = []\n",
    "b = soup.find_all('td', class_=\"wind\")\n",
    "b\n",
    "\n",
    "bb = []\n",
    "for bbc in b:\n",
    "    bbc = bbc.get_text().split('\\n')\n",
    "    bb.append(bbc)\n",
    "    \n",
    "bb\n",
    "\n",
    "w = bb[0:24]#wind\n",
    "\n",
    "\n",
    "c = []\n",
    "c = soup.find_all('td', class_=\"hr\")\n",
    "c\n",
    "\n",
    "cb = []\n",
    "for cbc in c:\n",
    "    cbc = cbc.get_text().split('\\n')\n",
    "    cb.append(cbc)\n",
    "    \n",
    "cb\n",
    "\n",
    "h=cb[0:24]  \n",
    "h#humidity\n",
    "\n",
    "\n",
    "d = []\n",
    "d = soup.find_all('td', class_=\"prob\")\n",
    "d\n",
    "\n",
    "db = []\n",
    "for dbc in d:\n",
    "    dbc = dbc.get_text().split('\\n')\n",
    "    db.append(dbc)\n",
    "    \n",
    "db\n",
    "\n",
    "p = db[0:24]  \n",
    "p  #press\n",
    "\n",
    "e = []\n",
    "e = soup.find_all('span' ,class_=\"thhip ico i0530 u3012\")\n",
    "e\n",
    "\n",
    "eb = []\n",
    "for ebc in e:\n",
    "    ebc = ebc.get_text().split('\\n')\n",
    "    eb.append(ebc)\n",
    "eb   \n",
    "\n",
    "es = []\n",
    "es = soup.find_all('span' ,class_=\"thhip ico i0530 u303n\")\n",
    "es\n",
    "\n",
    "for ebs in es:\n",
    "    ebs = ebs.get_text().split('\\n')\n",
    "    eb.append(ebs)\n",
    "    \n",
    "eb\n",
    "wc=eb[0:24]\n",
    "wc #weather condition\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'temperature':t,'wind':w ,'weather condition':wc,'humidity':h,'pressure':p})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d1410d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monument name</th>\n",
       "      <th>monument description</th>\n",
       "      <th>image URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taj Mahal, Agra</td>\n",
       "      <td>Enlisted in the Seven Wonders of the World, Th...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden Temple (Harmandir Sahib), Amritsar</td>\n",
       "      <td>The holiest shrine and pilgrimage place locate...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meenakshi Temple, Madurai</td>\n",
       "      <td>Meenakshi Temple is situated on the Southern b...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mysore Palace, Mysore</td>\n",
       "      <td>The Mysore Palace is a famous historical monum...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway of India, Mumbai</td>\n",
       "      <td>Even though Mumbai is famous for its Bollywood...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Red Fort, New Delhi</td>\n",
       "      <td>Declared as the UNESCO’s World Heritage Site, ...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hawa Mahal, Jaipur</td>\n",
       "      <td>Explore a blend of beauty and Rajasthan cultur...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qutub Minar, New Delhi</td>\n",
       "      <td>Discover one of the tallest towers in the worl...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanchi Stupa, Sanchi</td>\n",
       "      <td>The beautiful and massive dome, Sanchi Stupa a...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charminar, Hyderabad</td>\n",
       "      <td>No visit to Hyderabad should be complete witho...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                monument name  \\\n",
       "0                             Taj Mahal, Agra   \n",
       "1  Golden Temple (Harmandir Sahib), Amritsar    \n",
       "2                   Meenakshi Temple, Madurai   \n",
       "3                       Mysore Palace, Mysore   \n",
       "4                    Gateway of India, Mumbai   \n",
       "5                         Red Fort, New Delhi   \n",
       "6                          Hawa Mahal, Jaipur   \n",
       "7                      Qutub Minar, New Delhi   \n",
       "8                        Sanchi Stupa, Sanchi   \n",
       "9                        Charminar, Hyderabad   \n",
       "\n",
       "                                monument description  \\\n",
       "0  Enlisted in the Seven Wonders of the World, Th...   \n",
       "1  The holiest shrine and pilgrimage place locate...   \n",
       "2  Meenakshi Temple is situated on the Southern b...   \n",
       "3  The Mysore Palace is a famous historical monum...   \n",
       "4  Even though Mumbai is famous for its Bollywood...   \n",
       "5  Declared as the UNESCO’s World Heritage Site, ...   \n",
       "6  Explore a blend of beauty and Rajasthan cultur...   \n",
       "7  Discover one of the tallest towers in the worl...   \n",
       "8  The beautiful and massive dome, Sanchi Stupa a...   \n",
       "9  No visit to Hyderabad should be complete witho...   \n",
       "\n",
       "                                           image URL  \n",
       "0  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "1  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "2  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "3  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "4  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "5  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "6  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "7  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "8  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "9  http://www.puredestinations.co.uk/wp-content/u...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a python program to scrape monument name, monument description, image URL from puredestinations.co.uk\n",
    "\n",
    "import  requests\n",
    "from  bs4 import BeautifulSoup\n",
    "page = requests.get('https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/')\n",
    "soup = BeautifulSoup(page.content)\n",
    "\n",
    "monument_name=[]\n",
    "for m in soup.find_all('div', class_=\"blog--single__content column--3-4 u-spacing-third\"):\n",
    "    monument_name.append(m.text.split('\\n')[3:32:3])\n",
    "\n",
    "monument_name#name\n",
    "\n",
    "monument_names=monument_name.pop(0)\n",
    "\n",
    "monument_names#imp\n",
    "\n",
    "\n",
    "monument_desc=[]\n",
    "\n",
    "for md in soup.find_all('div', class_=\"blog--single__content column--3-4 u-spacing-third\"):\n",
    "    monument_desc.append(md.text.split('\\n')[4:35:3])\n",
    "\n",
    "monument_desc\n",
    "monument_descs=monument_desc.pop(0)\n",
    "\n",
    "zx = monument_descs.pop(10)\n",
    "\n",
    "monument_descs  #imp\n",
    "\n",
    "vedio = []\n",
    "for a in soup.find_all('img',class_=\"alignnone size-full wp-image-36626 lazyload\") :\n",
    "    vedio.append(a['data-src'])\n",
    "    \n",
    "for b in soup.find_all('img',class_=\"alignnone size-full wp-image-36628 lazyload\") :\n",
    "    vedio.append(b['data-src'])\n",
    "    \n",
    "for c in soup.find_all('img',class_=\"alignnone size-full wp-image-36630 lazyload\") :\n",
    "    vedio.append(c['data-src'])\n",
    "    \n",
    "for d in soup.find_all('img',class_=\"alignnone size-full wp-image-36631 lazyload\") :\n",
    "    vedio.append(d['data-src'])\n",
    "    \n",
    "for e in soup.find_all('img',class_=\"alignnone size-full wp-image-36632 lazyload\") :\n",
    "    vedio.append(e['data-src'])\n",
    "    \n",
    "for f in soup.find_all('img',class_=\"alignnone size-full wp-image-36623 lazyload\") :\n",
    "    vedio.append(f['data-src'])\n",
    "    \n",
    "for g in soup.find_all('img',class_=\"alignnone size-full wp-image-36634 lazyload\") :\n",
    "    vedio.append(g['data-src'])\n",
    "    \n",
    "for h in soup.find_all('img',class_=\"alignnone size-full wp-image-36636 lazyload\") :\n",
    "    vedio.append(h['data-src'])\n",
    "    \n",
    "for i in soup.find_all('img',class_=\"alignnone size-full wp-image-36637 lazyload\") :\n",
    "    vedio.append(i['data-src'])\n",
    "    \n",
    "for j in soup.find_all('img',class_=\"alignnone size-full wp-image-36646 lazyload\") :\n",
    "    vedio.append(j['data-src'])\n",
    "    \n",
    "    \n",
    "vedio\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'monument name':monument_names,'monument description':monument_descs,'image URL':vedio})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ba93b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af218f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40909675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa96ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e741ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a48da59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
